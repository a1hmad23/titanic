{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f637515a-9b16-436c-90db-05ef32b4a076",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d626e66-d1ac-490f-993d-6f8ec1b3349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63ed4129-5fb7-4436-8dde-73b86ae64221",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV = 'train.csv'\n",
    "TEST_CSV = 'test.csv'\n",
    "\n",
    "def load_data(csv_name):\n",
    "    csv_path = os.path.join('datasets', csv_name)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "704d9546-eb3c-4a98-b15b-642d5ab0a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = load_data(TRAIN_CSV)\n",
    "test_set = load_data(TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fb7c90e-030e-4626-a581-11c7709bb08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop(columns='Survived')\n",
    "y_train = train_set['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "740178d5-a987-4de0-9994-e8a8d9d519e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f01c5ed6-ab16-4339-8dec-4c12fa5ca675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Pclass       891 non-null    int64  \n",
      " 2   Name         891 non-null    object \n",
      " 3   Sex          891 non-null    object \n",
      " 4   Age          714 non-null    float64\n",
      " 5   SibSp        891 non-null    int64  \n",
      " 6   Parch        891 non-null    int64  \n",
      " 7   Ticket       891 non-null    object \n",
      " 8   Fare         891 non-null    float64\n",
      " 9   Cabin        204 non-null    object \n",
      " 10  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 76.7+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2a01ffd-d6fc-4d9a-b6d2-647d318931ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_deck_keep_cabin(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    s = df.iloc[:, 0].astype('string').str[0]      #astype string converts to pandas string datatype. this takes care of the Nan floats.\n",
    "    return pd.DataFrame({'Cabin':df.iloc[:, 0], 'Deck': s}, index=df.index)   # returns a df comprising of both the original cabin and deck columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9be21430-db75-4cd5-9067-24fede325e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sibsp_parch_binary(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out_df = (df > 0).astype(int)\n",
    "    out_df.columns = df.columns\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9860f692-0186-4c14-9d28-d9a5c71c6529",
   "metadata": {},
   "source": [
    "#### title pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "310b00a3-756d-45c3-a99d-3583a8a22104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_title(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    s = df.iloc[:, 0].str.split(' ').apply(lambda x: x[1])\n",
    "    return pd.DataFrame({'Title': s}, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6f350a8a-ec46-448c-b6c0-48e96bab7269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_title(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    s = df.iloc[:, 0].replace({\n",
    "        'Capt.':'Military', \n",
    "        'Major.':'Military',\n",
    "        'Col.':'Military',\n",
    "        'Jonkheer.':'Noble',\n",
    "        'the Countess':'Noble',\n",
    "        'Don.':'Noble',\n",
    "        'Lady':'Noble',\n",
    "        'Sir':'Noble',\n",
    "        'Mlle.':'Noble',\n",
    "        'Ms.':'Noble',\n",
    "        'Mme.':'Noble'\n",
    "    })\n",
    "\n",
    "    return pd.DataFrame({'Title': s}, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1bc72d06-b854-4958-95e3-bb2bd2f83753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "title_pipeline = Pipeline([\n",
    "    ('make_title', FunctionTransformer(func=make_title, validate=False, feature_names_out=lambda self, input_features:['Title'])),\n",
    "    ('group_title', FunctionTransformer(func=group_title, validate=False, feature_names_out='one-to-one'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376206ac-d5dc-4736-b5da-b379b695add5",
   "metadata": {},
   "source": [
    "#### Fare Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a805463f-4e1c-44c4-98ed-a53e46b5ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fare_per_ticket(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    fare = df.iloc[:, 0]\n",
    "    ticket = df.iloc[:, 1]\n",
    "    ticket_counts = ticket.map(ticket.value_counts())\n",
    "    fare_per_ticket = fare / ticket_counts\n",
    "    return pd.DataFrame({'fare_per_ticket': fare_per_ticket, 'Ticket': ticket}, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c7b3f878-4279-4a63-9854-9544b957cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_pipeline = Pipeline([\n",
    "    ('fare_per_ticket', FunctionTransformer(func=fare_per_ticket, validate=False, feature_names_out=lambda self, input_features:['fare_per_ticket','Ticket'])),\n",
    "    ('cut_fare', FunctionTransformer(func=fare_cut, validate=False,\n",
    "                                    kw_args={'bins': [0, 6, 13, 20, 40, 80, 222],\n",
    "                                             'labels': [0, 1, 2, 3, 4, 5]},\n",
    "                                     feature_names_out='one-to-one'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe0746f-5c75-4810-abcd-84988183816c",
   "metadata": {},
   "source": [
    "def shared_cabin_ticket(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    ss = df.apply(df.value_counts())\n",
    "    return pd.DataFrame({'shared_cabin': ss.iloc[:, 0], 'shared_ticket': ss.iloc[:, 1]}, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2567973d-71a5-4e77-acbf-2dad45d13ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shared_cabin_ticket(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Expect df with two columns: [Cabin, Ticket]\n",
    "    cabin  = df.iloc[:, 0].astype(\"string\")\n",
    "    ticket = df.iloc[:, 1].astype(\"string\")\n",
    "\n",
    "    shared_cabin = cabin.map(cabin.value_counts().gt(1)).fillna(False).astype(int)\n",
    "    shared_ticket = ticket.map(ticket.value_counts().gt(1)).fillna(False).astype(int)\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\"shared_cabin\": shared_cabin, \"shared_ticket\": shared_ticket},\n",
    "        index=df.index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e5a61c94-a844-46ef-9015-759493666fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_cut(df:pd.DataFrame, bins, labels) -> pd.DataFrame:\n",
    "    s = df.iloc[:, 0]\n",
    "    cats = pd.cut(s, bins = bins, labels = labels, include_lowest=True, right=True)\n",
    "    cats.name = s.name\n",
    "    return pd.DataFrame(cats, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d535998a-2ef8-43d8-b0a5-9d8fa251a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fare_cut(df:pd.DataFrame, bins, labels) -> pd.DataFrame:\n",
    "    s = df.iloc[:, 0]\n",
    "    cats = pd.cut(s, bins = bins, labels = labels, include_lowest=True, right=True)\n",
    "    cats.name = s.name\n",
    "    return pd.DataFrame({'fare_per_ticket': cats, 'Ticket': df.iloc[:, 1]}, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "db418d3d-3f98-4c6f-a4e0-2ef52d25fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "features_ct = ColumnTransformer(\n",
    "    transformers = [\n",
    "        #Not one-to-one\n",
    "        ('make_deck_keep_cabin', FunctionTransformer(func=make_deck_keep_cabin, validate=False, feature_names_out = lambda self, input_features:['Cabin', 'Deck']), ['Cabin']),\n",
    "        ('SibSp_Parch_binary', FunctionTransformer(func=sibsp_parch_binary, validate=False, feature_names_out = 'one-to-one'), ['SibSp', 'Parch']),\n",
    "        ('title_pipeline', title_pipeline, ['Name']),\n",
    "        ('fare_pipeline', fare_pipeline, ['Fare', 'Ticket']),\n",
    "        ('shared_cabin_ticket', FunctionTransformer(func=shared_cabin_ticket, validate=False, feature_names_out=lambda self, input_features:['shared_cabin', 'shared_ticket']), ['Cabin', 'Ticket']),\n",
    "        ('age_cut', FunctionTransformer(func=age_cut, validate=False, feature_names_out='one-to-one', kw_args={'bins': [0, 12, 17, 24, 44, 64, float('inf')], 'labels': [0, 1, 2, 3, 4, 5]}), ['Age'])\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ").set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e6bca1d9-6cfc-4c29-ae2f-128a65cd89bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropper = FunctionTransformer(\n",
    "    lambda df: df.drop(columns=[\"Cabin\", \"Ticket\", \"PassengerId\"]),\n",
    "    validate=False,\n",
    "    feature_names_out=lambda self, in_feats: [c for c in in_feats if c not in [\"Cabin\",\"Ticket\",\"PassengerId\"]],\n",
    ")\n",
    "\n",
    "features_pipeline = Pipeline([\n",
    "    (\"features\", features_ct),\n",
    "    (\"dropper\", dropper),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f6eac92b-b138-4ab3-a42c-b31f011c32d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = features_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "15fccd99-5ebe-42c5-a981-ea914f3e0914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deck</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Title</th>\n",
       "      <th>fare_per_ticket</th>\n",
       "      <th>shared_cabin</th>\n",
       "      <th>shared_ticket</th>\n",
       "      <th>Age</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Miss.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rev.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Miss.</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Deck  SibSp  Parch  Title fare_per_ticket  shared_cabin  shared_ticket  \\\n",
       "0    <NA>      1      0    Mr.               1             0              0   \n",
       "1       C      1      0   Mrs.               4             0              0   \n",
       "2    <NA>      0      0  Miss.               1             0              0   \n",
       "3       C      1      0   Mrs.               3             1              1   \n",
       "4    <NA>      0      0    Mr.               1             0              0   \n",
       "..    ...    ...    ...    ...             ...           ...            ...   \n",
       "886  <NA>      0      0   Rev.               1             0              0   \n",
       "887     B      0      0  Miss.               3             0              0   \n",
       "888  <NA>      1      1  Miss.               1             0              1   \n",
       "889     C      0      0    Mr.               3             0              0   \n",
       "890  <NA>      0      0    Mr.               1             0              0   \n",
       "\n",
       "     Age  Pclass     Sex Embarked  \n",
       "0      2       3    male        S  \n",
       "1      3       1  female        C  \n",
       "2      3       3  female        S  \n",
       "3      3       1  female        S  \n",
       "4      3       3    male        S  \n",
       "..   ...     ...     ...      ...  \n",
       "886    3       2    male        S  \n",
       "887    2       1  female        S  \n",
       "888  NaN       3  female        S  \n",
       "889    3       1    male        C  \n",
       "890    3       3    male        Q  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5e5f599b-4447-486d-900d-4369879ebbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   Deck             204 non-null    string  \n",
      " 1   SibSp            891 non-null    int64   \n",
      " 2   Parch            891 non-null    int64   \n",
      " 3   Title            891 non-null    object  \n",
      " 4   fare_per_ticket  891 non-null    category\n",
      " 5   shared_cabin     891 non-null    int64   \n",
      " 6   shared_ticket    891 non-null    int64   \n",
      " 7   Age              714 non-null    category\n",
      " 8   Pclass           891 non-null    int64   \n",
      " 9   Sex              891 non-null    object  \n",
      " 10  Embarked         889 non-null    object  \n",
      "dtypes: category(2), int64(5), object(3), string(1)\n",
      "memory usage: 64.9+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c3d208b5-5897-412f-910c-51d84d586e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = ['Deck', 'Title', 'Sex', 'Embarked']\n",
    "impute_cols = ['Deck', 'Age', 'Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6ed7d796-1297-4c60-955a-894781bec2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "impute_encode = ColumnTransformer([\n",
    "    ('impute_cat', SimpleImputer(strategy='most_frequent'), impute_cols),\n",
    "    ('one_hot', OneHotEncoder(), one_hot_cols),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5b2c7637-0a4f-424b-b81a-79362a877fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_missing(df):\n",
    "    # Replace pd.NA with np.nan everywhere\n",
    "    df = df.replace({pd.NA: np.nan})\n",
    "    # Force pandas extension types -> numpy dtypes\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_string_dtype(df[col]) or pd.api.types.is_object_dtype(df[col]):\n",
    "            df[col] = df[col].astype(\"object\")  # object dtype with np.nan\n",
    "        elif pd.api.types.is_integer_dtype(df[col]):\n",
    "            df[col] = df[col].astype(\"float\")   # float dtype with np.nan\n",
    "    return df\n",
    "\n",
    "nan_fixer = FunctionTransformer(fix_missing, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9eafdfca-d754-441c-a258-228daafa57ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Pipeline([\n",
    "    ('nan_fixer', nan_fixer),\n",
    "    ('add_remove_features_pipeline', features_pipeline),\n",
    "    ('impute_encode_ct', impute_encode)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c7a57682-7532-4c2b-8830-1c8d54d39b3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "boolean value of NA is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[31m-----------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[164]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m X_train2 = \u001b[43mpreprocessing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\titanic\\my_env\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\titanic\\my_env\\Lib\\site-packages\\sklearn\\pipeline.py:731\u001b[39m, in \u001b[36mPipeline.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    725\u001b[39m last_step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    726\u001b[39m     step_idx=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - \u001b[32m1\u001b[39m,\n\u001b[32m    727\u001b[39m     step_params=routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    728\u001b[39m     all_params=params,\n\u001b[32m    729\u001b[39m )\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(last_step, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m731\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlast_step\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m        \u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    735\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m last_step.fit(Xt, y, **last_step_params[\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m]).transform(\n\u001b[32m    736\u001b[39m         Xt, **last_step_params[\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    737\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\titanic\\my_env\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\titanic\\my_env\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\titanic\\my_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:996\u001b[39m, in \u001b[36mColumnTransformer.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    994\u001b[39m     routed_params = \u001b[38;5;28mself\u001b[39m._get_empty_routing()\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_fit_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[32m   1005\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_fitted_transformers([])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\titanic\\my_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:897\u001b[39m, in \u001b[36mColumnTransformer._call_func_on_transformers\u001b[39m\u001b[34m(self, X, y, func, column_as_labels, routed_params)\u001b[39m\n\u001b[32m    885\u001b[39m             extra_args = {}\n\u001b[32m    886\u001b[39m         jobs.append(\n\u001b[32m    887\u001b[39m             delayed(func)(\n\u001b[32m    888\u001b[39m                 transformer=clone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[32m   (...)\u001b[39m\u001b[32m    894\u001b[39m             )\n\u001b[32m    895\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mExpected 2D array, got 1D array instead\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\titanic\\my_env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\titanic\\my_env\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\titanic\\my_env\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\titanic\\my_env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\titanic\\my_env\\Lib\\site-packages\\sklearn\\pipeline.py:1540\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1541\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1542\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1543\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1544\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\titanic\\my_env\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\titanic\\my_env\\Lib\\site-packages\\sklearn\\base.py:894\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    879\u001b[39m         warnings.warn(\n\u001b[32m    880\u001b[39m             (\n\u001b[32m    881\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    889\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    890\u001b[39m         )\n\u001b[32m    892\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    893\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n\u001b[32m    895\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    896\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    897\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\titanic\\my_env\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\titanic\\my_env\\Lib\\site-packages\\sklearn\\impute\\_base.py:453\u001b[39m, in \u001b[36mSimpleImputer.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    449\u001b[39m     \u001b[38;5;28mself\u001b[39m.statistics_ = \u001b[38;5;28mself\u001b[39m._sparse_fit(\n\u001b[32m    450\u001b[39m         X, \u001b[38;5;28mself\u001b[39m.strategy, \u001b[38;5;28mself\u001b[39m.missing_values, fill_value\n\u001b[32m    451\u001b[39m     )\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m     \u001b[38;5;28mself\u001b[39m.statistics_ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dense_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmissing_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\titanic\\my_env\\Lib\\site-packages\\sklearn\\impute\\_base.py:519\u001b[39m, in \u001b[36mSimpleImputer._dense_fit\u001b[39m\u001b[34m(self, X, strategy, missing_values, fill_value)\u001b[39m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_dense_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, strategy, missing_values, fill_value):\n\u001b[32m    518\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit the transformer on dense data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     missing_mask = \u001b[43m_get_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    520\u001b[39m     masked_X = ma.masked_array(X, mask=missing_mask)\n\u001b[32m    522\u001b[39m     \u001b[38;5;28msuper\u001b[39m()._fit_indicator(missing_mask)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\titanic\\my_env\\Lib\\site-packages\\sklearn\\utils\\_mask.py:58\u001b[39m, in \u001b[36m_get_mask\u001b[39m\u001b[34m(X, value_to_mask)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute the boolean mask X == value_to_mask.\u001b[39;00m\n\u001b[32m     40\u001b[39m \n\u001b[32m     41\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     53\u001b[39m \u001b[33;03m    Missing mask.\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp.issparse(X):\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# For all cases apart of a sparse input where we need to reconstruct\u001b[39;00m\n\u001b[32m     57\u001b[39m     \u001b[38;5;66;03m# a sparse output\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_dense_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_to_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m Xt = _get_dense_mask(X.data, value_to_mask)\n\u001b[32m     62\u001b[39m sparse_constructor = sp.csr_matrix \u001b[38;5;28;01mif\u001b[39;00m X.format == \u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m sp.csc_matrix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\titanic\\my_env\\Lib\\site-packages\\sklearn\\utils\\_mask.py:31\u001b[39m, in \u001b[36m_get_dense_mask\u001b[39m\u001b[34m(X, value_to_mask)\u001b[39m\n\u001b[32m     28\u001b[39m         Xt = np.zeros(X.shape, dtype=\u001b[38;5;28mbool\u001b[39m)\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     30\u001b[39m         \u001b[38;5;66;03m# np.isnan does not work on object dtypes.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m         Xt = \u001b[43m_object_dtype_isnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     33\u001b[39m     Xt = X == value_to_mask\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\titanic\\my_env\\Lib\\site-packages\\sklearn\\utils\\fixes.py:55\u001b[39m, in \u001b[36m_object_dtype_isnan\u001b[39m\u001b[34m(X)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_object_dtype_isnan\u001b[39m(X):\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/missing.pyx:392\u001b[39m, in \u001b[36mpandas._libs.missing.NAType.__bool__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: boolean value of NA is ambiguous"
     ]
    }
   ],
   "source": [
    "X_train2 = preprocessing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c5f46e-6266-4f83-a786-1d186e9ee849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
